Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
/home/jtjohn26/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:1010: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.14s/it]
Device set to use cuda:0
Map:   0%|          | 0/6125 [00:00<?, ? examples/s]Map:  69%|██████▉   | 4245/6125 [00:00<00:00, 41596.65 examples/s]Map: 100%|██████████| 6125/6125 [00:00<00:00, 41796.33 examples/s]
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
